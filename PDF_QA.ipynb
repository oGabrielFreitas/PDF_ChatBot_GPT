{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: You exceeded your current quota, please check your plan and billing details..\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m llm \u001b[39m=\u001b[39m OpenAI()\n\u001b[1;32m      3\u001b[0m \u001b[39m# llm.model_name=\"text-babbage-001\"\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[39mprint\u001b[39m(llm(\u001b[39m\"\u001b[39;49m\u001b[39mtell me a joke\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n",
      "File \u001b[0;32m~/TCC/LangChain/env/lib/python3.10/site-packages/langchain/llms/base.py:338\u001b[0m, in \u001b[0;36mBaseLLM.__call__\u001b[0;34m(self, prompt, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(prompt, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    332\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    333\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mArgument `prompt` is expected to be a string. Instead found \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    334\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(prompt)\u001b[39m}\u001b[39;00m\u001b[39m. If you want to run the LLM on multiple prompts, use \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    335\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`generate` instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    336\u001b[0m     )\n\u001b[1;32m    337\u001b[0m \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m--> 338\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate([prompt], stop\u001b[39m=\u001b[39;49mstop, callbacks\u001b[39m=\u001b[39;49mcallbacks, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    339\u001b[0m     \u001b[39m.\u001b[39mgenerations[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m]\n\u001b[1;32m    340\u001b[0m     \u001b[39m.\u001b[39mtext\n\u001b[1;32m    341\u001b[0m )\n",
      "File \u001b[0;32m~/TCC/LangChain/env/lib/python3.10/site-packages/langchain/llms/base.py:206\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[0;34m(self, prompts, stop, callbacks, tags, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    205\u001b[0m     run_manager\u001b[39m.\u001b[39mon_llm_error(e)\n\u001b[0;32m--> 206\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    207\u001b[0m run_manager\u001b[39m.\u001b[39mon_llm_end(output)\n\u001b[1;32m    208\u001b[0m \u001b[39mif\u001b[39;00m run_manager:\n",
      "File \u001b[0;32m~/TCC/LangChain/env/lib/python3.10/site-packages/langchain/llms/base.py:198\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[0;34m(self, prompts, stop, callbacks, tags, **kwargs)\u001b[0m\n\u001b[1;32m    193\u001b[0m run_manager \u001b[39m=\u001b[39m callback_manager\u001b[39m.\u001b[39mon_llm_start(\n\u001b[1;32m    194\u001b[0m     dumpd(\u001b[39mself\u001b[39m), prompts, invocation_params\u001b[39m=\u001b[39mparams, options\u001b[39m=\u001b[39moptions\n\u001b[1;32m    195\u001b[0m )\n\u001b[1;32m    196\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    197\u001b[0m     output \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 198\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_generate(\n\u001b[1;32m    199\u001b[0m             prompts, stop\u001b[39m=\u001b[39;49mstop, run_manager\u001b[39m=\u001b[39;49mrun_manager, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    200\u001b[0m         )\n\u001b[1;32m    201\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    202\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate(prompts, stop\u001b[39m=\u001b[39mstop, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    203\u001b[0m     )\n\u001b[1;32m    204\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    205\u001b[0m     run_manager\u001b[39m.\u001b[39mon_llm_error(e)\n",
      "File \u001b[0;32m~/TCC/LangChain/env/lib/python3.10/site-packages/langchain/llms/openai.py:326\u001b[0m, in \u001b[0;36mBaseOpenAI._generate\u001b[0;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    324\u001b[0m     choices\u001b[39m.\u001b[39mextend(response[\u001b[39m\"\u001b[39m\u001b[39mchoices\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m    325\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 326\u001b[0m     response \u001b[39m=\u001b[39m completion_with_retry(\u001b[39mself\u001b[39;49m, prompt\u001b[39m=\u001b[39;49m_prompts, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams)\n\u001b[1;32m    327\u001b[0m     choices\u001b[39m.\u001b[39mextend(response[\u001b[39m\"\u001b[39m\u001b[39mchoices\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m    328\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstreaming:\n\u001b[1;32m    329\u001b[0m     \u001b[39m# Can't update token usage if streaming\u001b[39;00m\n",
      "File \u001b[0;32m~/TCC/LangChain/env/lib/python3.10/site-packages/langchain/llms/openai.py:106\u001b[0m, in \u001b[0;36mcompletion_with_retry\u001b[0;34m(llm, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[39m@retry_decorator\u001b[39m\n\u001b[1;32m    103\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_completion_with_retry\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m    104\u001b[0m     \u001b[39mreturn\u001b[39;00m llm\u001b[39m.\u001b[39mclient\u001b[39m.\u001b[39mcreate(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 106\u001b[0m \u001b[39mreturn\u001b[39;00m _completion_with_retry(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/TCC/LangChain/env/lib/python3.10/site-packages/tenacity/__init__.py:289\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(f)\n\u001b[1;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_f\u001b[39m(\u001b[39m*\u001b[39margs: t\u001b[39m.\u001b[39mAny, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw: t\u001b[39m.\u001b[39mAny) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m t\u001b[39m.\u001b[39mAny:\n\u001b[0;32m--> 289\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(f, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n",
      "File \u001b[0;32m~/TCC/LangChain/env/lib/python3.10/site-packages/tenacity/__init__.py:389\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoSleep):\n\u001b[1;32m    388\u001b[0m     retry_state\u001b[39m.\u001b[39mprepare_for_next_attempt()\n\u001b[0;32m--> 389\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msleep(do)\n\u001b[1;32m    390\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    391\u001b[0m     \u001b[39mreturn\u001b[39;00m do\n",
      "File \u001b[0;32m~/TCC/LangChain/env/lib/python3.10/site-packages/tenacity/nap.py:31\u001b[0m, in \u001b[0;36msleep\u001b[0;34m(seconds)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msleep\u001b[39m(seconds: \u001b[39mfloat\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     26\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[39m    Sleep strategy that delays execution for a given number of seconds.\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \n\u001b[1;32m     29\u001b[0m \u001b[39m    This is the default strategy, and may be mocked out for unit testing.\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m     time\u001b[39m.\u001b[39;49msleep(seconds)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    }
   ],
   "source": [
    "llm = OpenAI()\n",
    "\n",
    "# llm.model_name=\"text-babbage-001\"\n",
    "\n",
    "\n",
    "print(llm(\"tell me a joke\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.question_answering import load_qa_chain\n",
    "\n",
    "# load document\n",
    "loader = PyPDFLoader(\"./PDFs/REGIMENTO_UFSM.pdf\")\n",
    "documents = loader.load()\n",
    "\n",
    "### For multiple documents \n",
    "# loaders = [....]\n",
    "# documents = []\n",
    "# for loader in loaders:\n",
    "#     documents.extend(loader.load())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = load_qa_chain(llm=OpenAI(), chain_type=\"map_reduce\")\n",
    "query = \"O que é o conselho universitário?\"\n",
    "chain.run(input_documents=documents, question=query)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testanto Uso de Chunks e Splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load document\n",
    "loader = PyPDFLoader(\"./PDFs/REGIMENTO_UFSM.pdf\")\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 930, which is longer than the specified 800\n",
      "Created a chunk of size 1247, which is longer than the specified 800\n",
      "Created a chunk of size 1273, which is longer than the specified 800\n",
      "Created a chunk of size 1368, which is longer than the specified 800\n",
      "Created a chunk of size 887, which is longer than the specified 800\n",
      "Created a chunk of size 1082, which is longer than the specified 800\n",
      "Created a chunk of size 944, which is longer than the specified 800\n",
      "Created a chunk of size 1034, which is longer than the specified 800\n",
      "Created a chunk of size 1346, which is longer than the specified 800\n",
      "Created a chunk of size 1148, which is longer than the specified 800\n",
      "Created a chunk of size 1317, which is longer than the specified 800\n",
      "Created a chunk of size 1547, which is longer than the specified 800\n",
      "Created a chunk of size 1150, which is longer than the specified 800\n",
      "Created a chunk of size 1097, which is longer than the specified 800\n",
      "Created a chunk of size 1085, which is longer than the specified 800\n",
      "Created a chunk of size 1655, which is longer than the specified 800\n",
      "Created a chunk of size 1136, which is longer than the specified 800\n",
      "Created a chunk of size 863, which is longer than the specified 800\n",
      "Created a chunk of size 1138, which is longer than the specified 800\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "text_splitter = CharacterTextSplitter(        \n",
    "    separator = \"Art.\",\n",
    "    # separator = \"\\n\\n\",\n",
    "\n",
    "    chunk_size = 800,\n",
    "    chunk_overlap  = 0,\n",
    "    # length_function = len,\n",
    ")\n",
    "\n",
    "# text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "\n",
    "texts = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PERGUNTA\n",
    "# query = \"Ao o que compete a pró-reitoria de pós-graduação?\"\n",
    "query = \"quem pode expedir certificados de cursos de Pós-Graduação?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":2})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: You exceeded your current quota, please check your plan and billing details..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: You exceeded your current quota, please check your plan and billing details..\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m retriever\u001b[39m.\u001b[39;49mget_relevant_documents(query)\n",
      "File \u001b[0;32m~/TCC/LangChain/env/lib/python3.10/site-packages/langchain/vectorstores/base.py:392\u001b[0m, in \u001b[0;36mVectorStoreRetriever.get_relevant_documents\u001b[0;34m(self, query)\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_relevant_documents\u001b[39m(\u001b[39mself\u001b[39m, query: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[Document]:\n\u001b[1;32m    391\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msearch_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msimilarity\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 392\u001b[0m         docs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvectorstore\u001b[39m.\u001b[39;49msimilarity_search(query, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msearch_kwargs)\n\u001b[1;32m    393\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msearch_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msimilarity_score_threshold\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    394\u001b[0m         docs_and_similarities \u001b[39m=\u001b[39m (\n\u001b[1;32m    395\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvectorstore\u001b[39m.\u001b[39msimilarity_search_with_relevance_scores(\n\u001b[1;32m    396\u001b[0m                 query, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msearch_kwargs\n\u001b[1;32m    397\u001b[0m             )\n\u001b[1;32m    398\u001b[0m         )\n",
      "File \u001b[0;32m~/TCC/LangChain/env/lib/python3.10/site-packages/langchain/vectorstores/chroma.py:182\u001b[0m, in \u001b[0;36mChroma.similarity_search\u001b[0;34m(self, query, k, filter, **kwargs)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msimilarity_search\u001b[39m(\n\u001b[1;32m    166\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    167\u001b[0m     query: \u001b[39mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m    171\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[Document]:\n\u001b[1;32m    172\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Run similarity search with Chroma.\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \n\u001b[1;32m    174\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[39m        List[Document]: List of documents most similar to the query text.\u001b[39;00m\n\u001b[1;32m    181\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 182\u001b[0m     docs_and_scores \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msimilarity_search_with_score(query, k, \u001b[39mfilter\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mfilter\u001b[39;49m)\n\u001b[1;32m    183\u001b[0m     \u001b[39mreturn\u001b[39;00m [doc \u001b[39mfor\u001b[39;00m doc, _ \u001b[39min\u001b[39;00m docs_and_scores]\n",
      "File \u001b[0;32m~/TCC/LangChain/env/lib/python3.10/site-packages/langchain/vectorstores/chroma.py:229\u001b[0m, in \u001b[0;36mChroma.similarity_search_with_score\u001b[0;34m(self, query, k, filter, **kwargs)\u001b[0m\n\u001b[1;32m    225\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__query_collection(\n\u001b[1;32m    226\u001b[0m         query_texts\u001b[39m=\u001b[39m[query], n_results\u001b[39m=\u001b[39mk, where\u001b[39m=\u001b[39m\u001b[39mfilter\u001b[39m\n\u001b[1;32m    227\u001b[0m     )\n\u001b[1;32m    228\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 229\u001b[0m     query_embedding \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_embedding_function\u001b[39m.\u001b[39;49membed_query(query)\n\u001b[1;32m    230\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__query_collection(\n\u001b[1;32m    231\u001b[0m         query_embeddings\u001b[39m=\u001b[39m[query_embedding], n_results\u001b[39m=\u001b[39mk, where\u001b[39m=\u001b[39m\u001b[39mfilter\u001b[39m\n\u001b[1;32m    232\u001b[0m     )\n\u001b[1;32m    234\u001b[0m \u001b[39mreturn\u001b[39;00m _results_to_docs_and_scores(results)\n",
      "File \u001b[0;32m~/TCC/LangChain/env/lib/python3.10/site-packages/langchain/embeddings/openai.py:316\u001b[0m, in \u001b[0;36mOpenAIEmbeddings.embed_query\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39membed_query\u001b[39m(\u001b[39mself\u001b[39m, text: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[\u001b[39mfloat\u001b[39m]:\n\u001b[1;32m    308\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Call out to OpenAI's embedding endpoint for embedding query text.\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \n\u001b[1;32m    310\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[39m        Embedding for the text.\u001b[39;00m\n\u001b[1;32m    315\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 316\u001b[0m     embedding \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_embedding_func(text, engine\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdeployment)\n\u001b[1;32m    317\u001b[0m     \u001b[39mreturn\u001b[39;00m embedding\n",
      "File \u001b[0;32m~/TCC/LangChain/env/lib/python3.10/site-packages/langchain/embeddings/openai.py:282\u001b[0m, in \u001b[0;36mOpenAIEmbeddings._embedding_func\u001b[0;34m(self, text, engine)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mendswith(\u001b[39m\"\u001b[39m\u001b[39m001\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    279\u001b[0m     \u001b[39m# See: https://github.com/openai/openai-python/issues/418#issuecomment-1525939500\u001b[39;00m\n\u001b[1;32m    280\u001b[0m     \u001b[39m# replace newlines, which can negatively affect performance.\u001b[39;00m\n\u001b[1;32m    281\u001b[0m     text \u001b[39m=\u001b[39m text\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 282\u001b[0m \u001b[39mreturn\u001b[39;00m embed_with_retry(\n\u001b[1;32m    283\u001b[0m     \u001b[39mself\u001b[39;49m,\n\u001b[1;32m    284\u001b[0m     \u001b[39minput\u001b[39;49m\u001b[39m=\u001b[39;49m[text],\n\u001b[1;32m    285\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_invocation_params,\n\u001b[1;32m    286\u001b[0m )[\n\u001b[1;32m    287\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    288\u001b[0m ][\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39membedding\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/TCC/LangChain/env/lib/python3.10/site-packages/langchain/embeddings/openai.py:64\u001b[0m, in \u001b[0;36membed_with_retry\u001b[0;34m(embeddings, **kwargs)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[39m@retry_decorator\u001b[39m\n\u001b[1;32m     61\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_embed_with_retry\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m     62\u001b[0m     \u001b[39mreturn\u001b[39;00m embeddings\u001b[39m.\u001b[39mclient\u001b[39m.\u001b[39mcreate(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m---> 64\u001b[0m \u001b[39mreturn\u001b[39;00m _embed_with_retry(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/TCC/LangChain/env/lib/python3.10/site-packages/tenacity/__init__.py:289\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(f)\n\u001b[1;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_f\u001b[39m(\u001b[39m*\u001b[39margs: t\u001b[39m.\u001b[39mAny, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw: t\u001b[39m.\u001b[39mAny) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m t\u001b[39m.\u001b[39mAny:\n\u001b[0;32m--> 289\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(f, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n",
      "File \u001b[0;32m~/TCC/LangChain/env/lib/python3.10/site-packages/tenacity/__init__.py:389\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoSleep):\n\u001b[1;32m    388\u001b[0m     retry_state\u001b[39m.\u001b[39mprepare_for_next_attempt()\n\u001b[0;32m--> 389\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msleep(do)\n\u001b[1;32m    390\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    391\u001b[0m     \u001b[39mreturn\u001b[39;00m do\n",
      "File \u001b[0;32m~/TCC/LangChain/env/lib/python3.10/site-packages/tenacity/nap.py:31\u001b[0m, in \u001b[0;36msleep\u001b[0;34m(seconds)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msleep\u001b[39m(seconds: \u001b[39mfloat\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     26\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[39m    Sleep strategy that delays execution for a given number of seconds.\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \n\u001b[1;32m     29\u001b[0m \u001b[39m    This is the default strategy, and may be mocked out for unit testing.\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m     time\u001b[39m.\u001b[39;49msleep(seconds)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "retriever.get_relevant_documents(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: You exceeded your current quota, please check your plan and billing details..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: You exceeded your current quota, please check your plan and billing details..\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m qa \u001b[39m=\u001b[39m RetrievalQA\u001b[39m.\u001b[39mfrom_chain_type(\n\u001b[1;32m      2\u001b[0m     llm\u001b[39m=\u001b[39mOpenAI(model_name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtext-babbage-001\u001b[39m\u001b[39m'\u001b[39m), chain_type\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mstuff\u001b[39m\u001b[39m\"\u001b[39m, retriever\u001b[39m=\u001b[39mretriever, return_source_documents\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m----> 3\u001b[0m result \u001b[39m=\u001b[39m qa({\u001b[39m\"\u001b[39;49m\u001b[39mquery\u001b[39;49m\u001b[39m\"\u001b[39;49m: query})\n\u001b[1;32m      4\u001b[0m \u001b[39mprint\u001b[39m(result)\n",
      "File \u001b[0;32m~/TCC/LangChain/env/lib/python3.10/site-packages/langchain/chains/base.py:149\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, include_run_info)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    148\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 149\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    150\u001b[0m run_manager\u001b[39m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    151\u001b[0m final_outputs: Dict[\u001b[39mstr\u001b[39m, Any] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_outputs(\n\u001b[1;32m    152\u001b[0m     inputs, outputs, return_only_outputs\n\u001b[1;32m    153\u001b[0m )\n",
      "File \u001b[0;32m~/TCC/LangChain/env/lib/python3.10/site-packages/langchain/chains/base.py:143\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, include_run_info)\u001b[0m\n\u001b[1;32m    137\u001b[0m run_manager \u001b[39m=\u001b[39m callback_manager\u001b[39m.\u001b[39mon_chain_start(\n\u001b[1;32m    138\u001b[0m     dumpd(\u001b[39mself\u001b[39m),\n\u001b[1;32m    139\u001b[0m     inputs,\n\u001b[1;32m    140\u001b[0m )\n\u001b[1;32m    141\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    142\u001b[0m     outputs \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 143\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(inputs, run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[1;32m    144\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    145\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(inputs)\n\u001b[1;32m    146\u001b[0m     )\n\u001b[1;32m    147\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    148\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m~/TCC/LangChain/env/lib/python3.10/site-packages/langchain/chains/retrieval_qa/base.py:119\u001b[0m, in \u001b[0;36mBaseRetrievalQA._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    116\u001b[0m _run_manager \u001b[39m=\u001b[39m run_manager \u001b[39mor\u001b[39;00m CallbackManagerForChainRun\u001b[39m.\u001b[39mget_noop_manager()\n\u001b[1;32m    117\u001b[0m question \u001b[39m=\u001b[39m inputs[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_key]\n\u001b[0;32m--> 119\u001b[0m docs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_docs(question)\n\u001b[1;32m    120\u001b[0m answer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcombine_documents_chain\u001b[39m.\u001b[39mrun(\n\u001b[1;32m    121\u001b[0m     input_documents\u001b[39m=\u001b[39mdocs, question\u001b[39m=\u001b[39mquestion, callbacks\u001b[39m=\u001b[39m_run_manager\u001b[39m.\u001b[39mget_child()\n\u001b[1;32m    122\u001b[0m )\n\u001b[1;32m    124\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_source_documents:\n",
      "File \u001b[0;32m~/TCC/LangChain/env/lib/python3.10/site-packages/langchain/chains/retrieval_qa/base.py:181\u001b[0m, in \u001b[0;36mRetrievalQA._get_docs\u001b[0;34m(self, question)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_docs\u001b[39m(\u001b[39mself\u001b[39m, question: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[Document]:\n\u001b[0;32m--> 181\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretriever\u001b[39m.\u001b[39;49mget_relevant_documents(question)\n",
      "File \u001b[0;32m~/TCC/LangChain/env/lib/python3.10/site-packages/langchain/vectorstores/base.py:392\u001b[0m, in \u001b[0;36mVectorStoreRetriever.get_relevant_documents\u001b[0;34m(self, query)\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_relevant_documents\u001b[39m(\u001b[39mself\u001b[39m, query: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[Document]:\n\u001b[1;32m    391\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msearch_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msimilarity\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 392\u001b[0m         docs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvectorstore\u001b[39m.\u001b[39;49msimilarity_search(query, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msearch_kwargs)\n\u001b[1;32m    393\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msearch_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msimilarity_score_threshold\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    394\u001b[0m         docs_and_similarities \u001b[39m=\u001b[39m (\n\u001b[1;32m    395\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvectorstore\u001b[39m.\u001b[39msimilarity_search_with_relevance_scores(\n\u001b[1;32m    396\u001b[0m                 query, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msearch_kwargs\n\u001b[1;32m    397\u001b[0m             )\n\u001b[1;32m    398\u001b[0m         )\n",
      "File \u001b[0;32m~/TCC/LangChain/env/lib/python3.10/site-packages/langchain/vectorstores/chroma.py:182\u001b[0m, in \u001b[0;36mChroma.similarity_search\u001b[0;34m(self, query, k, filter, **kwargs)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msimilarity_search\u001b[39m(\n\u001b[1;32m    166\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    167\u001b[0m     query: \u001b[39mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m    171\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[Document]:\n\u001b[1;32m    172\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Run similarity search with Chroma.\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \n\u001b[1;32m    174\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[39m        List[Document]: List of documents most similar to the query text.\u001b[39;00m\n\u001b[1;32m    181\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 182\u001b[0m     docs_and_scores \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msimilarity_search_with_score(query, k, \u001b[39mfilter\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mfilter\u001b[39;49m)\n\u001b[1;32m    183\u001b[0m     \u001b[39mreturn\u001b[39;00m [doc \u001b[39mfor\u001b[39;00m doc, _ \u001b[39min\u001b[39;00m docs_and_scores]\n",
      "File \u001b[0;32m~/TCC/LangChain/env/lib/python3.10/site-packages/langchain/vectorstores/chroma.py:229\u001b[0m, in \u001b[0;36mChroma.similarity_search_with_score\u001b[0;34m(self, query, k, filter, **kwargs)\u001b[0m\n\u001b[1;32m    225\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__query_collection(\n\u001b[1;32m    226\u001b[0m         query_texts\u001b[39m=\u001b[39m[query], n_results\u001b[39m=\u001b[39mk, where\u001b[39m=\u001b[39m\u001b[39mfilter\u001b[39m\n\u001b[1;32m    227\u001b[0m     )\n\u001b[1;32m    228\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 229\u001b[0m     query_embedding \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_embedding_function\u001b[39m.\u001b[39;49membed_query(query)\n\u001b[1;32m    230\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__query_collection(\n\u001b[1;32m    231\u001b[0m         query_embeddings\u001b[39m=\u001b[39m[query_embedding], n_results\u001b[39m=\u001b[39mk, where\u001b[39m=\u001b[39m\u001b[39mfilter\u001b[39m\n\u001b[1;32m    232\u001b[0m     )\n\u001b[1;32m    234\u001b[0m \u001b[39mreturn\u001b[39;00m _results_to_docs_and_scores(results)\n",
      "File \u001b[0;32m~/TCC/LangChain/env/lib/python3.10/site-packages/langchain/embeddings/openai.py:316\u001b[0m, in \u001b[0;36mOpenAIEmbeddings.embed_query\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39membed_query\u001b[39m(\u001b[39mself\u001b[39m, text: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[\u001b[39mfloat\u001b[39m]:\n\u001b[1;32m    308\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Call out to OpenAI's embedding endpoint for embedding query text.\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \n\u001b[1;32m    310\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[39m        Embedding for the text.\u001b[39;00m\n\u001b[1;32m    315\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 316\u001b[0m     embedding \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_embedding_func(text, engine\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdeployment)\n\u001b[1;32m    317\u001b[0m     \u001b[39mreturn\u001b[39;00m embedding\n",
      "File \u001b[0;32m~/TCC/LangChain/env/lib/python3.10/site-packages/langchain/embeddings/openai.py:282\u001b[0m, in \u001b[0;36mOpenAIEmbeddings._embedding_func\u001b[0;34m(self, text, engine)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mendswith(\u001b[39m\"\u001b[39m\u001b[39m001\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    279\u001b[0m     \u001b[39m# See: https://github.com/openai/openai-python/issues/418#issuecomment-1525939500\u001b[39;00m\n\u001b[1;32m    280\u001b[0m     \u001b[39m# replace newlines, which can negatively affect performance.\u001b[39;00m\n\u001b[1;32m    281\u001b[0m     text \u001b[39m=\u001b[39m text\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 282\u001b[0m \u001b[39mreturn\u001b[39;00m embed_with_retry(\n\u001b[1;32m    283\u001b[0m     \u001b[39mself\u001b[39;49m,\n\u001b[1;32m    284\u001b[0m     \u001b[39minput\u001b[39;49m\u001b[39m=\u001b[39;49m[text],\n\u001b[1;32m    285\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_invocation_params,\n\u001b[1;32m    286\u001b[0m )[\n\u001b[1;32m    287\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    288\u001b[0m ][\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39membedding\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/TCC/LangChain/env/lib/python3.10/site-packages/langchain/embeddings/openai.py:64\u001b[0m, in \u001b[0;36membed_with_retry\u001b[0;34m(embeddings, **kwargs)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[39m@retry_decorator\u001b[39m\n\u001b[1;32m     61\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_embed_with_retry\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m     62\u001b[0m     \u001b[39mreturn\u001b[39;00m embeddings\u001b[39m.\u001b[39mclient\u001b[39m.\u001b[39mcreate(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m---> 64\u001b[0m \u001b[39mreturn\u001b[39;00m _embed_with_retry(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/TCC/LangChain/env/lib/python3.10/site-packages/tenacity/__init__.py:289\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(f)\n\u001b[1;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_f\u001b[39m(\u001b[39m*\u001b[39margs: t\u001b[39m.\u001b[39mAny, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw: t\u001b[39m.\u001b[39mAny) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m t\u001b[39m.\u001b[39mAny:\n\u001b[0;32m--> 289\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(f, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n",
      "File \u001b[0;32m~/TCC/LangChain/env/lib/python3.10/site-packages/tenacity/__init__.py:389\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoSleep):\n\u001b[1;32m    388\u001b[0m     retry_state\u001b[39m.\u001b[39mprepare_for_next_attempt()\n\u001b[0;32m--> 389\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msleep(do)\n\u001b[1;32m    390\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    391\u001b[0m     \u001b[39mreturn\u001b[39;00m do\n",
      "File \u001b[0;32m~/TCC/LangChain/env/lib/python3.10/site-packages/tenacity/nap.py:31\u001b[0m, in \u001b[0;36msleep\u001b[0;34m(seconds)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msleep\u001b[39m(seconds: \u001b[39mfloat\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     26\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[39m    Sleep strategy that delays execution for a given number of seconds.\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \n\u001b[1;32m     29\u001b[0m \u001b[39m    This is the default strategy, and may be mocked out for unit testing.\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m     time\u001b[39m.\u001b[39;49msleep(seconds)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=OpenAI(model_name='text-babbage-001'), chain_type=\"stuff\", retriever=retriever, return_source_documents=True)\n",
    "result = qa({\"query\": query})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "A pró-reitoria de pós-graduação compete coordenar, supervisionar e dirigir a execução das atividades do Ensino de Graduação, estimular e acompanhar as atividades acadêmicas em geral, e especificamente: analisar as propostas de cursos e suas alterações, regulamentar a nível da Instituição, a legislação do Ensino de Graduação com proposição e reformulação de normas, e orientar, coordenar e avaliar as atividades acadêmicas em geral.\n"
     ]
    }
   ],
   "source": [
    "print(result['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select which embeddings we want to use\n",
    "embeddings = OpenAIEmbeddings()\n",
    "# create the vectorestore to use as the index\n",
    "db = Chroma.from_documents(texts, embeddings)\n",
    "# expose this index in a retriever interface\n",
    "retriever = db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":2})\n",
    "# create a chain to answer questions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(vectorstore=<langchain.vectorstores.chroma.Chroma object at 0x7f14aa6aa380>, search_type='similarity', search_kwargs={'k': 2})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='5\\nREGIMENTO GERAL 88 -  UFSM\\nSeção II\\nDo Conselho De Ensino, Pesquisa E Extensão\\nArt. 6º O Conselho de Ensino, Pesquisa e Extensão, composto na forma do a rt.\\n18 do Estatuto , é o órgão superior deliberativo e consultivo da UFSM, para os assuntos de\\nEnsino, Pesquisa e Extensão.\\nArt. 7º As competências do Conselho de Ensino, Pesquisa e Extensão são\\nestabelecidas no a rt. 19 do Estatuto .\\nParágrafo único –  As normas de Funcionamento deste Conselho são\\nestabelecidas em Regimento Interno Próprio.\\nSeção III\\nDo Conselho De Curadores\\nArt. 8º O Conselho de Curadores composto na forma do Artigo 21 do Estatuto\\né o órgão de controle e fiscalização econômico-financeiro da UFSM.\\nArt. 9º As competências do Conselho de Curadores são estabelecidas no a rt.\\n22 do Estatuto .\\nParágrafo único – As normas de funcionamento deste Conselho são\\nestabelecidas em Regimento Interno Próprio.\\nSeção IV\\nDa Secretaria Dos Órgãos Superiores\\nArt. 10. Os serviços burocráticos dos Colegiados Superiores ficarão a cargo de\\numa Secretaria que comportará uma estr utura definida em Regimento Próprio.\\nSeção V\\nDa Reitoria\\nArt. 11.  A Reitoria é o órgão que executa, coordena e superintende todas as\\natividades universitárias.\\nParágrafo único – Para atender o disposto neste artigo a Reitoria contará com\\nos seguintes órgãos:\\nI. Gabinete do Reitor;\\nII. Gabinete do Vice-Reitor;' metadata={'source': './PDFs/REGIMENTO_UFSM.pdf', 'page': 4}\n"
     ]
    }
   ],
   "source": [
    "print(texts[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='. 14. À Pró-Reitoria de Administração  (PRA ) compete coordenar, fiscalizar,\\nsupervisionar e dirigir os serviços adminis trativos da Universidade e especificamente:\\nII - executar a política  definida pelo Conselho Universitário referente a área\\nadministrativa;\\nIII - promover a integração dos diversos órgãos na área administrativa;IV - praticar atos de gestão administrativa;V - coordenar as atividades administrativas nas áreas de Administração\\nFinanceira e Contabilidade, Material e Patrimônio, Recursos Humanos,\\nServiços Gerais, Processamento de Dados, Arquivo e Microfilmagem.\\nParágrafo único – Ficam vinculados à Pró-Reitoria de Administração, para fins\\nde supervisão administrativa, os seguintes órgãos: Departamento de Pessoal, Departamento\\nde Material e Patrimônio, Departamento de Contabilidade e Finanças, Núcleo de\\nProcessamento de Dados, Prefeitura da Cidade Universitária, Imprensa Universitária eBiblioteca Central.' metadata={'source': './PDFs/REGIMENTO_UFSM.pdf', 'page': 5}\n"
     ]
    }
   ],
   "source": [
    "print(texts[11])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "# Suponha que você tenha uma variável chamada \"documento\" que contém o texto completo\n",
    "documento = \"Texto completo do documento Art. 1 Lorem ipsum... Sec. 2 Lorem ipsum... Par. 3 Lorem ipsum...\"\n",
    "\n",
    "# Defina uma lista de separadores que deseja utilizar\n",
    "separadores = [\"Art.\", \"\\nArt.\", \"UNIVERSITÁRIA\\nArt.\" ,\"UNIVERSITÁRIO\\nArt.\"]\n",
    "\n",
    "# Crie uma expressão regular para identificar qualquer um dos separadores\n",
    "regex_separadores = '|'.join(map(re.escape, separadores))\n",
    "\n",
    "# Use a expressão regular como separador na instanciação do CharacterTextSplitter\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=regex_separadores,\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=0\n",
    ")\n",
    "\n",
    "# Divida o documento em pedaços usando o método split_documents(), mantendo os separadores no texto original\n",
    "pedacos = text_splitter.split_documents(documents)\n",
    "\n",
    "# Agora você tem a lista de pedaços de texto, onde cada pedaço termina exatamente antes de cada ocorrência de um dos separadores\n",
    "# Faça o que for necessário com os pedaços (por exemplo, imprima-os)\n",
    "# for pedaco in pedacos:\n",
    "#     print(pedaco)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='5\\nREGIMENTO GERAL 88 -  UFSM\\nSeção II\\nDo Conselho De Ensino, Pesquisa E Extensão\\nArt. 6º O Conselho de Ensino, Pesquisa e Extensão, composto na forma do a rt.\\n18 do Estatuto , é o órgão superior deliberativo e consultivo da UFSM, para os assuntos de\\nEnsino, Pesquisa e Extensão.\\nArt. 7º As competências do Conselho de Ensino, Pesquisa e Extensão são\\nestabelecidas no a rt. 19 do Estatuto .\\nParágrafo único –  As normas de Funcionamento deste Conselho são\\nestabelecidas em Regimento Interno Próprio.\\nSeção III\\nDo Conselho De Curadores\\nArt. 8º O Conselho de Curadores composto na forma do Artigo 21 do Estatuto\\né o órgão de controle e fiscalização econômico-financeiro da UFSM.\\nArt. 9º As competências do Conselho de Curadores são estabelecidas no a rt.\\n22 do Estatuto .\\nParágrafo único – As normas de funcionamento deste Conselho são\\nestabelecidas em Regimento Interno Próprio.\\nSeção IV\\nDa Secretaria Dos Órgãos Superiores\\nArt. 10. Os serviços burocráticos dos Colegiados Superiores ficarão a cargo de\\numa Secretaria que comportará uma estr utura definida em Regimento Próprio.\\nSeção V\\nDa Reitoria\\nArt. 11.  A Reitoria é o órgão que executa, coordena e superintende todas as\\natividades universitárias.\\nParágrafo único – Para atender o disposto neste artigo a Reitoria contará com\\nos seguintes órgãos:\\nI. Gabinete do Reitor;\\nII. Gabinete do Vice-Reitor;', metadata={'source': './PDFs/REGIMENTO_UFSM.pdf', 'page': 4})"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pedacos[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Art\\\\.|\\\\\\nArt\\\\.|UNIVERSITÁRIA\\\\\\nArt\\\\.|UNIVERSITÁRIO\\\\\\nArt\\\\.'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regex_separadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
